{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voc_to_yolo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lvC3GE_VyeFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convert VOC to yolo format"
      ]
    },
    {
      "metadata": {
        "id": "aPM2cCiayeFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Based on https://github.com/pjreddie/darknet/blob/master/scripts/voc_label.py\n",
        "\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from os import listdir, getcwd\n",
        "from os.path import join\n",
        "\n",
        "\n",
        "\n",
        "def convert(size, box):\n",
        "    dw = 1./(size[0])\n",
        "    dh = 1./(size[1])\n",
        "    x = (box[0] + box[1])/2.0 - 1\n",
        "    y = (box[2] + box[3])/2.0 - 1\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x*dw\n",
        "    w = w*dw\n",
        "    y = y*dh\n",
        "    h = h*dh\n",
        "    return (x,y,w,h)\n",
        "\n",
        "def convert_annotation(img_file, classes, voc_annotations_path, yolo_annotations_path):\n",
        "    img_file_name = '.'.join(img_file.split('.')[:-1])\n",
        "    in_file = open(os.path.join(voc_annotations_path, img_file_name + '.xml'), 'r')\n",
        "    out_file = open(os.path.join(yolo_annotations_path, img_file_name + '.txt'), 'w')\n",
        "    tree=ET.parse(in_file)\n",
        "    root = tree.getroot()\n",
        "    size = root.find('size')\n",
        "    w = int(size.find('width').text)\n",
        "    h = int(size.find('height').text)\n",
        "\n",
        "    for obj in root.iter('object'):\n",
        "        difficult = obj.find('difficult').text\n",
        "        cls = obj.find('name').text\n",
        "        if cls not in classes or int(difficult)==1:\n",
        "            continue\n",
        "        cls_id = classes.index(cls)\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
        "        bb = convert((w,h), b)\n",
        "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lw0JNFOVyeFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download face detection dataset with VOC annotations\n",
        "%cd /content/\n",
        "! wget https://s3-eu-west-1.amazonaws.com/training-dl/face_detection_dataset.zip\n",
        "! unzip face_detection_dataset.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OJ0x0z7yeFf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start with a dir with images and VOC annotations folders and a list of classes names\n",
        "darknet_path = '/content/darknet'\n",
        "\n",
        "\n",
        "train_images_path = './face_detection_dataset/train/images'\n",
        "train_voc_annotations_path = './face_detection_dataset/train/annotations'\n",
        "\n",
        "val_images_path = './face_detection_dataset/test/images'\n",
        "val_voc_annotations_path = './face_detection_dataset/test/annotations'\n",
        "\n",
        "\n",
        "classes = [\"Face\"]\n",
        "\n",
        "# Generate: labels, voc.data voc.labels, train.txt val.txt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l2--I1TEyeFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create destination dir\n",
        "destination_path = './yolo_faces_tiny'\n",
        "relative_path_from_darknet = '../yolo_faces_tiny'\n",
        "\n",
        "yolo_annotations_path = os.path.join(destination_path, 'images')\n",
        "\n",
        "if not os.path.exists(destination_path):\n",
        "    os.makedirs(destination_path)\n",
        "if not os.path.exists(yolo_annotations_path):\n",
        "    os.makedirs(yolo_annotations_path)\n",
        "if not os.path.exists(os.path.join(destination_path, 'backup')):\n",
        "    os.makedirs(os.path.join(destination_path, 'backup'))\n",
        "if not os.path.exists(os.path.join(destination_path, 'images')):\n",
        "    os.makedirs(os.path.join(destination_path, 'images'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GEGU0xt9yeFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def copytree(src, dst, symlinks=False, ignore=None):\n",
        "  ''' Overwrite copytree to support existing dirs\n",
        "  '''\n",
        "    for item in os.listdir(src):\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(dst, item)\n",
        "        if os.path.isdir(s):\n",
        "            shutil.copytree(s, d, symlinks, ignore)\n",
        "        else:\n",
        "            shutil.copy2(s, d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPiW0n4eyeFl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#copy train images dir. Pending to improve checking extension\n",
        "copytree(train_images_path, os.path.join(destination_path, 'images'))\n",
        "\n",
        "#get list of train images filenames\n",
        "images_train = os.listdir(train_images_path)\n",
        "\n",
        "# Select only compatible files\n",
        "images_train = [img_name for img_name in images_train if str.lower(img_name.split('.')[-1]) in ['jpg','jpeg','png']]\n",
        "\n",
        "# List of annotations files available\n",
        "annotations_train = [str.lower(f) for f in os.listdir(train_voc_annotations_path)]\n",
        "\n",
        "# create train labels and train.txt\n",
        "train_files_list = []\n",
        "for img_file in images_train:\n",
        "    img_file_name = '.'.join(img_file.split('.')[:-1])\n",
        "    if str.lower(img_file_name+'.xml') in annotations_train: # if have annotation file\n",
        "        convert_annotation(img_file, classes, train_voc_annotations_path, os.path.join(destination_path, 'images'))\n",
        "        train_files_list += [os.path.join(relative_path_from_darknet, 'images', img_file)]\n",
        "    \n",
        "with open(os.path.join(destination_path, 'train.txt'), 'w') as f:\n",
        "    for item in train_files_list:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "! head ./yolo_faces_tiny/train.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iKHFIb-AyeFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#copy val images dir. Pending to improve checking extension\n",
        "copytree(val_images_path, os.path.join(destination_path, 'images'))\n",
        "\n",
        "#get list of train images filenames\n",
        "images_val = os.listdir(val_images_path)\n",
        "\n",
        "# Select only compatible files\n",
        "images_val = [img_name for img_name in images_val if str.lower(img_name.split('.')[-1]) in ['jpg','jpeg','png']]\n",
        "\n",
        "# List of annotations files available\n",
        "annotations_val = [str.lower(f) for f in os.listdir(val_voc_annotations_path)]\n",
        "\n",
        "\n",
        "# create valid labels and valid.txt\n",
        "val_files_list = []\n",
        "for img_file in images_val:\n",
        "    img_file_name = '.'.join(img_file.split('.')[:-1])\n",
        "    if str.lower(img_file_name+'.xml') in annotations_val: # if have annotation file\n",
        "        convert_annotation(img_file, classes, val_voc_annotations_path, os.path.join(destination_path, 'images'))\n",
        "        val_files_list += [os.path.join(relative_path_from_darknet, 'images',  img_file)]\n",
        "\n",
        "with open(os.path.join(destination_path, 'val.txt'), 'w') as f:\n",
        "    for item in val_files_list:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "! head ./yolo_faces_tiny/val.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6yCd_94yeFp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create voc.names with the classes\n",
        "\n",
        "with open(os.path.join(destination_path, 'voc.names'), 'w') as labels_file:\n",
        "    for c in classes:\n",
        "        labels_file.write(c+'\\n')\n",
        "\n",
        "! cat ./yolo_faces_tiny/voc.names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CO_JKm9oyeFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create voc.data with the configuration\n",
        "\n",
        "with open(os.path.join(destination_path, 'voc.data'), 'w') as data_file:\n",
        "    data_file.write('classes = '+str(len(classes))+'\\n')\n",
        "    data_file.write('train = '+os.path.join(relative_path_from_darknet,'train.txt')+'\\n')\n",
        "    data_file.write('valid = '+os.path.join(relative_path_from_darknet,'val.txt')+'\\n')\n",
        "    data_file.write('names = '+os.path.join(relative_path_from_darknet,'voc.names')+'\\n')\n",
        "    data_file.write('backup = '+os.path.join(relative_path_from_darknet,'backup'))\n",
        "\n",
        "! cat ./yolo_faces_tiny/voc.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hD32hUJAyeFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copy cgf file and configure it\n",
        "\n",
        "#shutil.copyfile(os.path.join(darknet_path,'cfg','yolov3-tiny_obj.cfg'), os.path.join(destination_path,'yolo-obj.cfg'))  \n",
        "\n",
        "# To use the full model. Copy cfg of full model\n",
        "#shutil.copyfile(os.path.join(darknet_path,'cfg','yolov3.cfg'), os.path.join(destination_path,'yolo-obj.cfg'))\n",
        "\n",
        "\n",
        "#! cat ./yolo_faces_tiny/yolov3-tiny_obj.cfg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXpf6lInyeF3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Configure yolo-obj.cfg\n",
        "# Based on https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects\n",
        "\n",
        "#change line batch to batch=64\n",
        "#change line subdivisions to subdivisions=8\n",
        "#change line max_batches to (classes*2000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "#change line classes=80 to your number of objects in each of 3 [yolo]-layers: LINES: 610, 696, 783\n",
        "#change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer. Lines: 603, 689, 776\n",
        "\n",
        "#So if classes=1 then should be filters=18. If classes=2 then write filters=21.\n",
        "\n",
        "#Generally filters depends on the classes, coords and number of masks, \n",
        "#  i.e. filters=(classes + coords + 1)*<number of mask>, where mask is indices of anchors.\n",
        "#  If mask is absence, then filters=(classes + coords + 1)*num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nd62EK__yeF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L9-SESIcyeF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the tiny model\n",
        "# cd darknet\n",
        "# ./darknet detector train ../yolo_faces_tiny/voc.data ../yolo_faces_tiny/yolov3-tiny-obj.cfg yolov3-tiny.conv.15 -dont_show\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Mopii_HyeF8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the full yolo model\n",
        "# cd darknet\n",
        "# ./darknet detector train ../yolo_faces/voc.data ../yolo_faces/yolo-obj.cfg darknet53.conv.74\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}