{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert VOC to yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/pjreddie/darknet/blob/master/scripts/voc_label.py\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def convert_annotation(img_file, classes, voc_annotations_path, yolo_annotations_path):\n",
    "    img_file_name = '.'.join(img_file.split('.')[:-1])\n",
    "    in_file = open(os.path.join(voc_annotations_path, img_file_name + '.xml'), 'r')\n",
    "    out_file = open(os.path.join(yolo_annotations_path, img_file_name + '.txt'), 'w')\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((w,h), b)\n",
    "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download face detection dataset with VOC annotations\n",
    "%cd /content/\n",
    "! wget https://s3-eu-west-1.amazonaws.com/training-dl/face_detection_dataset.zip\n",
    "! unzip face_detection_dataset.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a dir with images and VOC annotations folders and a list of classes names\n",
    "darknet_path = './darknet'\n",
    "\n",
    "\n",
    "train_images_path = './face_detection_dataset/train/images'\n",
    "train_voc_annotations_path = './face_detection_dataset/train/annotations'\n",
    "\n",
    "val_images_path = './face_detection_dataset/test/images'\n",
    "val_voc_annotations_path = './face_detection_dataset/test/annotations'\n",
    "\n",
    "\n",
    "classes = [\"Face\"]\n",
    "\n",
    "# Generate: labels, voc.data voc.labels, train.txt val.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create destination dir\n",
    "destination_path = './yolo_faces_tiny'\n",
    "relative_path_from_darknet = '../yolo_faces_tiny'\n",
    "\n",
    "yolo_annotations_path = os.path.join(destination_path, 'images')\n",
    "\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "if not os.path.exists(yolo_annotations_path):\n",
    "    os.makedirs(yolo_annotations_path)\n",
    "if not os.path.exists(os.path.join(destination_path, 'backup')):\n",
    "    os.makedirs(os.path.join(destination_path, 'backup'))\n",
    "if not os.path.exists(os.path.join(destination_path, 'images')):\n",
    "    os.makedirs(os.path.join(destination_path, 'images'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copytree(src, dst, symlinks=False, ignore=None):\n",
    "    for item in os.listdir(src):\n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d, symlinks, ignore)\n",
    "        else:\n",
    "            shutil.copy2(s, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy train images dir. Pending to improve checking extension\n",
    "copytree(train_images_path, os.path.join(destination_path, 'images'))\n",
    "\n",
    "#get list of train images filenames\n",
    "images_train = os.listdir(train_images_path)\n",
    "\n",
    "# Select only compatible files\n",
    "images_train = [img_name for img_name in images_train if str.lower(img_name.split('.')[-1]) in ['jpg','jpeg','png']]\n",
    "\n",
    "# List of annotations files available\n",
    "annotations_train = [str.lower(f) for f in os.listdir(train_voc_annotations_path)]\n",
    "\n",
    "# create train labels and train.txt\n",
    "train_files_list = []\n",
    "for img_file in images_train:\n",
    "    img_file_name = '.'.join(img_file.split('.')[:-1])\n",
    "    if str.lower(img_file_name+'.xml') in annotations_train: # if have annotation file\n",
    "        convert_annotation(img_file, classes, train_voc_annotations_path, os.path.join(destination_path, 'images'))\n",
    "        train_files_list += [os.path.join(relative_path_from_darknet, 'images', img_file)]\n",
    "    \n",
    "with open(os.path.join(destination_path, 'train.txt'), 'w') as f:\n",
    "    for item in train_files_list:\n",
    "        f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy val images dir. Pending to improve checking extension\n",
    "copytree(val_images_path, os.path.join(destination_path, 'images'))\n",
    "\n",
    "#get list of train images filenames\n",
    "images_val = os.listdir(val_images_path)\n",
    "\n",
    "# Select only compatible files\n",
    "images_val = [img_name for img_name in images_val if str.lower(img_name.split('.')[-1]) in ['jpg','jpeg','png']]\n",
    "\n",
    "# List of annotations files available\n",
    "annotations_val = [str.lower(f) for f in os.listdir(val_voc_annotations_path)]\n",
    "\n",
    "\n",
    "# create valid labels and valid.txt\n",
    "val_files_list = []\n",
    "for img_file in images_val:\n",
    "    img_file_name = '.'.join(img_file.split('.')[:-1])\n",
    "    if str.lower(img_file_name+'.xml') in annotations_val: # if have annotation file\n",
    "        convert_annotation(img_file, classes, val_voc_annotations_path, os.path.join(destination_path, 'images'))\n",
    "        val_files_list += [os.path.join(relative_path_from_darknet, 'images',  img_file)]\n",
    "\n",
    "with open(os.path.join(destination_path, 'val.txt'), 'w') as f:\n",
    "    for item in val_files_list:\n",
    "        f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create voc.names with the classes\n",
    "\n",
    "with open(os.path.join(destination_path, 'voc.names'), 'w') as labels_file:\n",
    "    for c in classes:\n",
    "        labels_file.write(c+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create voc.data with the configuration\n",
    "\n",
    "with open(os.path.join(destination_path, 'voc.data'), 'w') as data_file:\n",
    "    data_file.write('classes = '+str(len(classes))+'\\n')\n",
    "    data_file.write('train = '+os.path.join(relative_path_from_darknet,'train.txt')+'\\n')\n",
    "    data_file.write('valid = '+os.path.join(relative_path_from_darknet,'val.txt')+'\\n')\n",
    "    data_file.write('names = '+os.path.join(relative_path_from_darknet,'voc.names')+'\\n')\n",
    "    data_file.write('backup = '+os.path.join(relative_path_from_darknet,'backup'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jorge/projects/training/yolo_faces/yolo-obj.cfg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy cgf file and configure it\n",
    "\n",
    "shutil.copyfile(os.path.join(darknet_path,'cfg','yolov3-tiny_obj.cfg'), os.path.join(destination_path,'yolo-obj.cfg'))  \n",
    "\n",
    "# To use the full model. Copy cfg of full model\n",
    "#shutil.copyfile(os.path.join(darknet_path,'cfg','yolov3.cfg'), os.path.join(destination_path,'yolo-obj.cfg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure yolo-obj.cfg\n",
    "# Based on https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects\n",
    "\n",
    "#change line batch to batch=64\n",
    "#change line subdivisions to subdivisions=8\n",
    "#change line max_batches to (classes*2000), f.e. max_batches=6000 if you train for 3 classes\n",
    "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
    "#change line classes=80 to your number of objects in each of 3 [yolo]-layers: LINES: 610, 696, 783\n",
    "#change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer. Lines: 603, 689, 776\n",
    "\n",
    "#So if classes=1 then should be filters=18. If classes=2 then write filters=21.\n",
    "\n",
    "#Generally filters depends on the classes, coords and number of masks, \n",
    "#  i.e. filters=(classes + coords + 1)*<number of mask>, where mask is indices of anchors.\n",
    "#  If mask is absence, then filters=(classes + coords + 1)*num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tiny model\n",
    "# cd darknet\n",
    "# ./darknet detector train ../yolo_faces_tiny/voc.data ../yolo_faces_tiny/yolov3-tiny-obj.cfg yolov3-tiny.conv.15 -dont_show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the full yolo model\n",
    "# cd darknet\n",
    "# ./darknet detector train ../yolo_faces/voc.data ../yolo_faces/yolo-obj.cfg darknet53.conv.74\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
