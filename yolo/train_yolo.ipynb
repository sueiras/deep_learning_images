{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHet4VdENII0"
   },
   "source": [
    "# Train a yolo model into colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIw3wNCSNII1"
   },
   "outputs": [],
   "source": [
    "# Download and unzip darknet for colab\n",
    "\n",
    "! wget https://s3-eu-west-1.amazonaws.com/training-dl/darknet.zip\n",
    "! unzip darknet.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6o5B3L4NII4"
   },
   "outputs": [],
   "source": [
    "# Download and unzip the yolo data prepared example\n",
    "%cd /content\n",
    "! wget https://s3-eu-west-1.amazonaws.com/training-dl/yolo_faces_tiny.zip\n",
    "! unzip yolo_faces_tiny.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N20c0qvBNII6"
   },
   "outputs": [],
   "source": [
    "# check config file\n",
    "! cat ./yolo_faces_tiny/yolov3-tiny-obj.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Xj7oa_ygM5u"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "G8ol87VJNII-",
    "outputId": "eab1d5fa-c035-4e3c-9158-17a4506d0e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/darknet\n",
      "nohup: redirecting stderr to stdout\n"
     ]
    }
   ],
   "source": [
    "# train model. send output to a file\n",
    "%cd darknet \n",
    "! nohup ./darknet detector train ../yolo_faces_tiny/voc.data ../yolo_faces_tiny/yolov3-tiny-obj.cfg yolov3-tiny.conv.15 -dont_show > train.log &\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "8KIBSXuBWmrg",
    "outputId": "021ffc40-0aaf-48c7-ca89-17f7a9f3f774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3995: 0.907111, 0.878187 avg loss, 0.000010 rate, 1.109599 seconds, 127840 images\n",
      " 3996: 1.171766, 0.907545 avg loss, 0.000010 rate, 1.087014 seconds, 127872 images\n",
      " 3997: 0.660691, 0.882860 avg loss, 0.000010 rate, 1.069572 seconds, 127904 images\n",
      " 3998: 0.623224, 0.856896 avg loss, 0.000010 rate, 1.012866 seconds, 127936 images\n",
      " 3999: 0.713591, 0.842565 avg loss, 0.000010 rate, 1.047932 seconds, 127968 images\n",
      " 4000: 0.853080, 0.843617 avg loss, 0.000010 rate, 1.110496 seconds, 128000 images\n"
     ]
    }
   ],
   "source": [
    "# monitor the training process \n",
    "# Check the log\n",
    "! tail -100 train.log | grep loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXdkA7d3gs5b"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "AhoclTXsgtMe",
    "outputId": "9dde770b-2a99-4589-8ca0-741faeba4195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer     filters    size              input                output\n",
      "   0 conv     16  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  16 0.150 BF\n",
      "   1 max          2 x 2 / 2   416 x 416 x  16   ->   208 x 208 x  16 0.003 BF\n",
      "   2 conv     32  3 x 3 / 1   208 x 208 x  16   ->   208 x 208 x  32 0.399 BF\n",
      "   3 max          2 x 2 / 2   208 x 208 x  32   ->   104 x 104 x  32 0.001 BF\n",
      "   4 conv     64  3 x 3 / 1   104 x 104 x  32   ->   104 x 104 x  64 0.399 BF\n",
      "   5 max          2 x 2 / 2   104 x 104 x  64   ->    52 x  52 x  64 0.001 BF\n",
      "   6 conv    128  3 x 3 / 1    52 x  52 x  64   ->    52 x  52 x 128 0.399 BF\n",
      "   7 max          2 x 2 / 2    52 x  52 x 128   ->    26 x  26 x 128 0.000 BF\n",
      "   8 conv    256  3 x 3 / 1    26 x  26 x 128   ->    26 x  26 x 256 0.399 BF\n",
      "   9 max          2 x 2 / 2    26 x  26 x 256   ->    13 x  13 x 256 0.000 BF\n",
      "  10 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512 0.399 BF\n",
      "  11 max          2 x 2 / 1    13 x  13 x 512   ->    13 x  13 x 512 0.000 BF\n",
      "  12 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024 1.595 BF\n",
      "  13 conv    256  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 256 0.089 BF\n",
      "  14 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512 0.399 BF\n",
      "  15 conv     18  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x  18 0.003 BF\n",
      "  16 yolo\n",
      "  17 route  13\n",
      "  18 conv    128  1 x 1 / 1    13 x  13 x 256   ->    13 x  13 x 128 0.011 BF\n",
      "  19 upsample            2x    13 x  13 x 128   ->    26 x  26 x 128\n",
      "  20 route  19 8\n",
      "  21 conv    256  3 x 3 / 1    26 x  26 x 384   ->    26 x  26 x 256 1.196 BF\n",
      "  22 conv     18  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x  18 0.006 BF\n",
      "  23 yolo\n",
      "Total BFLOPS 5.448 \n",
      " Allocate additional workspace_size = 12.46 MB \n",
      "Loading weights from ../yolo_faces_tiny/backup/yolov3-tiny-obj_1000.weights...\n",
      " seen 64 \n",
      "Done!\n",
      "../yolo_faces_tiny/images/0039.jpg: Predicted in 10.084000 milli-seconds.\n",
      "Face: 81%\n",
      "Face: 95%\n",
      "Face: 67%\n",
      "Not compiled with OpenCV, saving to predictions.png instead\n"
     ]
    }
   ],
   "source": [
    "# inference over a test image (0033 to 0040) with the weigths of the first 1000 iterations\n",
    "! ./darknet detector test ../yolo_faces_tiny/voc.data ../yolo_faces_tiny/yolov3-tiny-obj.cfg ../yolo_faces_tiny/backup/yolov3-tiny-obj_1000.weights ../yolo_faces_tiny/images/0039.jpg\n",
    "\n",
    "# Plot the predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "plt.imshow(plt.imread('./predictions.jpg'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "eEsS_-j7g5aX",
    "outputId": "f50c436a-0b29-4518-c226-277202c0ce7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "rGVyY4EowMC5",
    "outputId": "51271122-f851-4682-cb67-b681db9aa05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer     filters    size              input                output\n",
      "   0 conv     16  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  16 0.150 BF\n",
      "   1 max          2 x 2 / 2   416 x 416 x  16   ->   208 x 208 x  16 0.003 BF\n",
      "   2 conv     32  3 x 3 / 1   208 x 208 x  16   ->   208 x 208 x  32 0.399 BF\n",
      "   3 max          2 x 2 / 2   208 x 208 x  32   ->   104 x 104 x  32 0.001 BF\n",
      "   4 conv     64  3 x 3 / 1   104 x 104 x  32   ->   104 x 104 x  64 0.399 BF\n",
      "   5 max          2 x 2 / 2   104 x 104 x  64   ->    52 x  52 x  64 0.001 BF\n",
      "   6 conv    128  3 x 3 / 1    52 x  52 x  64   ->    52 x  52 x 128 0.399 BF\n",
      "   7 max          2 x 2 / 2    52 x  52 x 128   ->    26 x  26 x 128 0.000 BF\n",
      "   8 conv    256  3 x 3 / 1    26 x  26 x 128   ->    26 x  26 x 256 0.399 BF\n",
      "   9 max          2 x 2 / 2    26 x  26 x 256   ->    13 x  13 x 256 0.000 BF\n",
      "  10 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512 0.399 BF\n",
      "  11 max          2 x 2 / 1    13 x  13 x 512   ->    13 x  13 x 512 0.000 BF\n",
      "  12 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024 1.595 BF\n",
      "  13 conv    256  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 256 0.089 BF\n",
      "  14 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512 0.399 BF\n",
      "  15 conv     18  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x  18 0.003 BF\n",
      "  16 yolo\n",
      "  17 route  13\n",
      "  18 conv    128  1 x 1 / 1    13 x  13 x 256   ->    13 x  13 x 128 0.011 BF\n",
      "  19 upsample            2x    13 x  13 x 128   ->    26 x  26 x 128\n",
      "  20 route  19 8\n",
      "  21 conv    256  3 x 3 / 1    26 x  26 x 384   ->    26 x  26 x 256 1.196 BF\n",
      "  22 conv     18  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x  18 0.006 BF\n",
      "  23 yolo\n",
      "Total BFLOPS 5.448 \n",
      " Allocate additional workspace_size = 12.46 MB \n",
      "Loading weights from ../yolo_faces_tiny/backup/yolov3-tiny-obj_final.weights...\n",
      " seen 64 \n",
      "Done!\n",
      "../yolo_faces_tiny/images/0039.jpg: Predicted in 12.807000 milli-seconds.\n",
      "Face: 75%\n",
      "Face: 98%\n",
      "Face: 100%\n",
      "Face: 55%\n",
      "Face: 98%\n",
      "Not compiled with OpenCV, saving to predictions.png instead\n"
     ]
    }
   ],
   "source": [
    "# Optional: inference over a test image (0033 to 0040) with a final tiny weigths\n",
    "! ./darknet detector test ../yolo_faces_tiny/voc.data ../yolo_faces_tiny/yolov3-tiny-obj.cfg yolo_faces_tiny.weights ../yolo_faces_tiny/images/0039.jpg\n",
    "\n",
    "plt.imshow(plt.imread('./predictions.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "nXejLvDY6cpG",
    "outputId": "2fc75de9-b0c2-45ff-bfb3-d0c8a4091b60"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train_yolo.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
